{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster the Spire\n",
    "Will Wright"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Purpose and Context\n",
    "\n",
    "[todo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import shutil\n",
    "from os import listdir\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the data currently lives in several zipped tar.gz files within the 'zipped' folder.  These need to be extracted into an unzipped folder.\n",
    "\n",
    "**PROTIP:** If you have the files already extracted (as they are in the repo), skip this step to avoid the lengthy unpacking process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all(archives, extract_path, zip_format = \"gztar\"):\n",
    "    '''\n",
    "    input: path to zipped file archives, path to extract, and type of zipped file\n",
    "    output: unzipped contents of each zipped file within the extract path\n",
    "    '''\n",
    "    for filename in listdir(archives):\n",
    "        shutil.unpack_archive(archives+filename, extract_path, zip_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "extract_all(\"../data_raw/zipped/\",\"../data_raw/unzipped/\", \"gztar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start here if the files are already unzipped\n",
    "read_files = glob.glob(\"../data_raw/unzipped/*/*.json\", recursive = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To give more context about the data we're working with, lets see exactly how many raw game runs we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "279848"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(read_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost 280K games! We'll need to subset down to games for The Defect on Ascension 20 that resulted in wins before we can determine the relevant sample size though. In order to do that, we'll want to read these files together and use relevant JSON keys to narrow our focus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this approach creates a list of JSON strings from all the read_files\n",
    "output_list = []\n",
    "\n",
    "for f in read_files:\n",
    "    try:\n",
    "        with open(f, \"r\") as infile:\n",
    "            # test if the file isn't empty and that the name doesn't contain 'undefined' (1 file, contents are \"File doesn't exists)\")\n",
    "            if (os.path.getsize(f)>0) & (('undefined' in f)==False):\n",
    "                output_list.append(json.load(infile))\n",
    "            else:\n",
    "                pass\n",
    "    except UnicodeDecodeError: # some unicode can't be read so just don't load those games (I think it's a particular monster name)\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "279693"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(read_files)-len(output_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've excluded 155 games that were either empty, had unreadable unicode, or were 'undefined'.  It's possible that this may introduce some bias (e.g. removing relevant games with particular qualities), but given that this represents such a small volume of games relative to all 280K and I haven't seen any apparent bias in looking through a sample of the files, I don't think this should be a major concern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After more attempts to get the data into the right format, it looks like there is a single case where the JSON is wrapped in '[ ]'.  Since this game is for Ironclad, I'll simply remove from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "279693"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_list[:] = [s for s in output_list if str(s)[0]!='[']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "279692"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that single exception removed, we can now subset to a list of Defect games, which pass the conditions of being the Defect character, a victory, and Ascension 20.  Since it's possible that I'll want to expand this investigation to the other two characters later, I'll also set aside their games in their own lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Winning Ascension 20 games by character\n",
    "defect_asc20_win_games = []\n",
    "ironclad_asc20_win_games = []\n",
    "silent_asc20_win_games = []\n",
    "\n",
    "# Losing Ascension 20 games by character\n",
    "defect_asc20_lose_games = []\n",
    "ironclad_asc20_lose_games = []\n",
    "silent_asc20_lose_games = []\n",
    "\n",
    "for i in range(len(output_list)):\n",
    "    if output_list[i] is not None:\n",
    "        # test to ensure the game data has all the required elements (character, ascention level, and victory status)\n",
    "        if ('character_chosen' in dict(output_list[i])) and \\\n",
    "        ('ascension_level' in dict(output_list[i])) and \\\n",
    "        ('victory' in dict(output_list[i])):\n",
    "            \n",
    "            # DEFECT WINNING\n",
    "            if (output_list[i]['character_chosen']=='DEFECT') & \\\n",
    "            (output_list[i]['victory']==True) & \\\n",
    "            (output_list[i]['ascension_level']==20):\n",
    "                defect_asc20_win_games.append(output_list[i])\n",
    "            \n",
    "            # DEFECT LOSING\n",
    "            if (output_list[i]['character_chosen']=='DEFECT') & \\\n",
    "            (output_list[i]['victory']==False) & \\\n",
    "            (output_list[i]['ascension_level']==20):\n",
    "                defect_asc20_lose_games.append(output_list[i])\n",
    "            \n",
    "            # IRONCLAD WINNING  \n",
    "            if (output_list[i]['character_chosen']=='IRONCLAD') & \\\n",
    "            (output_list[i]['victory']==True) & \\\n",
    "            (output_list[i]['ascension_level']==20):\n",
    "                ironclad_asc20_win_games.append(output_list[i])\n",
    "                \n",
    "            # IRONCLAD LOSING  \n",
    "            if (output_list[i]['character_chosen']=='IRONCLAD') & \\\n",
    "            (output_list[i]['victory']==False) & \\\n",
    "            (output_list[i]['ascension_level']==20):\n",
    "                ironclad_asc20_lose_games.append(output_list[i])\n",
    "                \n",
    "            # SILENT WINNING  \n",
    "            if (output_list[i]['character_chosen']=='THE_SILENT') & \\\n",
    "            (output_list[i]['victory']==True) & \\\n",
    "            (output_list[i]['ascension_level']==20):\n",
    "                silent_asc20_win_games.append(output_list[i])\n",
    "                \n",
    "            # SILENT LOSING\n",
    "            if (output_list[i]['character_chosen']=='THE_SILENT') & \\\n",
    "            (output_list[i]['victory']==False) & \\\n",
    "            (output_list[i]['ascension_level']==20):\n",
    "                silent_asc20_lose_games.append(output_list[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm curious about character winrates.  Lets compare to the total games per character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate all summary statistics\n",
    "defect_winning = len(defect_asc20_win_games)\n",
    "defect_losing = len(defect_asc20_lose_games)\n",
    "defect_total = len(defect_asc20_win_games)+len(defect_asc20_lose_games)\n",
    "defect_winrate = defect_winning/defect_total\n",
    "\n",
    "# Calculate all summary statistics\n",
    "ironclad_winning = len(ironclad_asc20_win_games)\n",
    "ironclad_losing = len(ironclad_asc20_lose_games)\n",
    "ironclad_total = len(ironclad_asc20_win_games)+len(ironclad_asc20_lose_games)\n",
    "ironclad_winrate = ironclad_winning/ironclad_total\n",
    "\n",
    "# Calculate all summary statistics\n",
    "silent_winning = len(silent_asc20_win_games)\n",
    "silent_losing = len(silent_asc20_lose_games)\n",
    "silent_total = len(silent_asc20_win_games)+len(silent_asc20_lose_games)\n",
    "silent_winrate = silent_winning/silent_total\n",
    "\n",
    "\n",
    "asc20_games_summary = pd.DataFrame({'Character':['Defect','Ironclad','Silent'],\n",
    "                                    'Winning Games':[defect_winning,\n",
    "                                                     ironclad_winning,\n",
    "                                                     silent_winning],\n",
    "                                     'Total Games':[defect_total,\n",
    "                                                    ironclad_total,\n",
    "                                                    silent_total],\n",
    "                                     'Winrate':[defect_winrate,\n",
    "                                               ironclad_winrate,\n",
    "                                               silent_winrate]})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Character</th>\n",
       "      <th>Winning Games</th>\n",
       "      <th>Total Games</th>\n",
       "      <th>Winrate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Defect</td>\n",
       "      <td>1669</td>\n",
       "      <td>16863</td>\n",
       "      <td>0.098974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Ironclad</td>\n",
       "      <td>1716</td>\n",
       "      <td>14798</td>\n",
       "      <td>0.115962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Silent</td>\n",
       "      <td>1811</td>\n",
       "      <td>14278</td>\n",
       "      <td>0.126838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Character  Winning Games  Total Games   Winrate\n",
       "0    Defect           1669        16863  0.098974\n",
       "1  Ironclad           1716        14798  0.115962\n",
       "2    Silent           1811        14278  0.126838"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asc20_games_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would seem that although Defect is the most-played character, it has the lowest winrate.  This supports the claim that Defect is the hardest character (at least on Ascension 20).  In any case, we have 1669 victorious Defect Ascension 20 games, which should be adequate sample for clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to convert this list of JSON objects to a dataframe we can cluster.  Ideally, the shape of the data is one-row-per-game with columns for all the cards and relics. In order to do that, we'll want to create a vector of all unique cards and relics.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting Unique Cards and Relics  \n",
    "\n",
    "In order to get all unique cards and relics, we can simply pull all cards and relics from all games, then apply the `unique()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_game_decks = []\n",
    "all_game_relics = []\n",
    "\n",
    "for i in range(len(output_list)):\n",
    "    if output_list[i] is not None:\n",
    "        # ensure the run data has the deck and relics to avoid errors in rare cases\n",
    "        if ('master_deck' in dict(output_list[i])) and ('relics' in dict(output_list[i])):\n",
    "            all_game_decks.append(output_list[i]['master_deck'])\n",
    "            all_game_relics.append(output_list[i]['relics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Within each game, each card and relic needs to be pulled out into a flat list.\n",
    "all_cards = []\n",
    "\n",
    "for i in range(len(all_game_decks)):\n",
    "    for j in range(len(all_game_decks[i])):\n",
    "        all_cards.append(all_game_decks[i][j])\n",
    "        \n",
    "all_relics = []\n",
    "\n",
    "for i in range(len(all_game_relics)):\n",
    "    for j in range(len(all_game_relics[i])):\n",
    "        all_relics.append(all_game_relics[i][j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create unique lists\n",
    "unique_cards = list(np.unique(all_cards))\n",
    "unique_relics = list(np.unique(all_relics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3164"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_cards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "876"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_relics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we have 3164 unique cards and 876 unique relics.  This is a fair bit more than expected, so lets take a look at the head and tail of cards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6A',\n",
       " '6A+1',\n",
       " 'A Thousand Cuts',\n",
       " 'A Thousand Cuts+1',\n",
       " 'Abandon',\n",
       " 'Abandon+1',\n",
       " 'AbeCurse',\n",
       " 'AbsoluteMagnitude+1',\n",
       " 'Absolvement',\n",
       " 'Absolvement+1']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_cards[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vexMod:StarBlast',\n",
       " 'vexMod:StrikeStorm',\n",
       " 'vexMod:StrikeStorm+1',\n",
       " 'vexMod:Taunt+1',\n",
       " 'vexMod:TrainingStrike',\n",
       " 'vexMod:TrainingStrike+1',\n",
       " 'vexMod:UltimateCard',\n",
       " 'vexMod:VenomSigh',\n",
       " 'vexMod:VolumeVengeance']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_cards[-10:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This reveals two issues: there are the standard and \"+1\" versions of cards (players can upgrade cards once) as well as cards from game mods (essentially, player-made extensions of the game).  Thankfully, my domain expertise makes it fairly easy to know which cards aren't in the base game and it seems like most of the modded cards have a ':' in their name so they should be fairly easy to exclude.  \n",
    "\n",
    "After testing, it looks like there are a few other exceptions for specific mods that don't follow the usual 'mod:card' structure.  I'll go ahead and simply remove those cases as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_cards[:] = [s for s in unique_cards if '+' not in s \\\n",
    "                   and ':' not in s\\\n",
    "                   and 'animator_' not in s\\\n",
    "                   and 'Haku_' not in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "716"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_cards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In review of the new card list, I can still see some non-base cards, but I'm not too concerned with this affecting the final results due to the expected low frequency of those cards (0 in cases where the character isn't one of the base characters).  \n",
    "\n",
    "Next, the same cleansing will be applied to the relics. Generally speaking, relics have the same issue with mods as the cards, but there are not upgrades available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_relics[:] = [s for s in unique_relics if '_' not in s \\\n",
    "                   and ':' not in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "391"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_relics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, this isn't a perfect methodology, but since there are no flags for being a mod within the game data, it is difficult to use a single signal as a subsetting criteria to only the base game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "At this point, we can build a table of all unique cards and relics and then fill in Trues and Falses for whether the card was present per completed game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
