{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster the Spire\n",
    "Will Wright"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Purpose and Context\n",
    "\n",
    "[todo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import shutil\n",
    "from os import listdir\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import copy\n",
    "from heapq import nsmallest\n",
    "\n",
    "# increase viewable dataframe rows and columns\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.max_columns', 20)\n",
    "\n",
    "# set random seed\n",
    "random.seed(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the data currently lives in several zipped tar.gz files within the 'zipped' folder.  These need to be extracted into an unzipped folder.\n",
    "\n",
    "**PROTIP:** If you have the files already extracted (as they are in the repo), skip this step to avoid the lengthy unpacking process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all(archives, extract_path, zip_format = \"gztar\"):\n",
    "    '''\n",
    "    input: path to zipped file archives, path to extract, and type of zipped file\n",
    "    output: unzipped contents of each zipped file within the extract path\n",
    "    '''\n",
    "    for filename in listdir(archives):\n",
    "        shutil.unpack_archive(archives+filename, extract_path, zip_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "extract_all(\"../data_raw/zipped/\",\"../data_raw/unzipped/\", \"gztar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start here if the files are already unzipped\n",
    "read_files = glob.glob(\"../data_raw/unzipped/*/*.json\", recursive = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To give more context about the data we're working with, lets see exactly how many raw game runs we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "279848"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(read_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost 280K games! We'll need to subset down to games for The Defect on Ascension 20 that resulted in wins before we can determine the relevant sample size though. In order to do that, we'll want to read these files together and use relevant JSON keys to narrow our focus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this approach creates a list of JSON strings from all the read_files\n",
    "output_list = []\n",
    "\n",
    "for f in read_files:\n",
    "    try:\n",
    "        with open(f, \"r\") as infile:\n",
    "            # test if the file isn't empty and that the name doesn't contain 'undefined' (1 file, contents are \"File doesn't exists)\")\n",
    "            if (os.path.getsize(f)>0) & (('undefined' in f)==False):\n",
    "                output_list.append(json.load(infile))\n",
    "            else:\n",
    "                pass\n",
    "    except UnicodeDecodeError: # some unicode can't be read so just don't load those games (I think it's a particular monster name)\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "279693"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(read_files)-len(output_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've excluded 155 games that were either empty, had unreadable unicode, or were 'undefined'.  It's possible that this may introduce some bias (e.g. removing relevant games with particular qualities), but given that this represents such a small volume of games relative to all 280K and I haven't seen any apparent bias in looking through a sample of the files, I don't think this should be a major concern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After more attempts to get the data into the right format, it looks like there is a single case where the JSON is wrapped in '[ ]'.  Since this game is for Ironclad, I'll simply remove from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "279693"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_list[:] = [s for s in output_list if str(s)[0]!='[']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "279692"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that single exception removed, we can now subset to a list of Defect games, which pass the conditions of being the Defect character, a victory, and Ascension 20.  Since it's possible that I'll want to expand this investigation to the other two characters later, I'll also set aside their games in their own lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Winning Ascension 20 games by character\n",
    "defect_asc20_win_games = []\n",
    "ironclad_asc20_win_games = []\n",
    "silent_asc20_win_games = []\n",
    "\n",
    "# Losing Ascension 20 games by character\n",
    "defect_asc20_lose_games = []\n",
    "ironclad_asc20_lose_games = []\n",
    "silent_asc20_lose_games = []\n",
    "\n",
    "for i in range(len(output_list)):\n",
    "    if output_list[i] is not None:\n",
    "        # test to ensure the game data has all the required elements (character, ascention level, and victory status)\n",
    "        if ('character_chosen' in dict(output_list[i])) and \\\n",
    "        ('ascension_level' in dict(output_list[i])) and \\\n",
    "        ('victory' in dict(output_list[i])):\n",
    "            \n",
    "            # DEFECT WINNING\n",
    "            if (output_list[i]['character_chosen']=='DEFECT') & \\\n",
    "            (output_list[i]['victory']==True) & \\\n",
    "            (output_list[i]['ascension_level']==20):\n",
    "                defect_asc20_win_games.append(output_list[i])\n",
    "            \n",
    "            # DEFECT LOSING\n",
    "            if (output_list[i]['character_chosen']=='DEFECT') & \\\n",
    "            (output_list[i]['victory']==False) & \\\n",
    "            (output_list[i]['ascension_level']==20):\n",
    "                defect_asc20_lose_games.append(output_list[i])\n",
    "            \n",
    "            # IRONCLAD WINNING  \n",
    "            if (output_list[i]['character_chosen']=='IRONCLAD') & \\\n",
    "            (output_list[i]['victory']==True) & \\\n",
    "            (output_list[i]['ascension_level']==20):\n",
    "                ironclad_asc20_win_games.append(output_list[i])\n",
    "                \n",
    "            # IRONCLAD LOSING  \n",
    "            if (output_list[i]['character_chosen']=='IRONCLAD') & \\\n",
    "            (output_list[i]['victory']==False) & \\\n",
    "            (output_list[i]['ascension_level']==20):\n",
    "                ironclad_asc20_lose_games.append(output_list[i])\n",
    "                \n",
    "            # SILENT WINNING  \n",
    "            if (output_list[i]['character_chosen']=='THE_SILENT') & \\\n",
    "            (output_list[i]['victory']==True) & \\\n",
    "            (output_list[i]['ascension_level']==20):\n",
    "                silent_asc20_win_games.append(output_list[i])\n",
    "                \n",
    "            # SILENT LOSING\n",
    "            if (output_list[i]['character_chosen']=='THE_SILENT') & \\\n",
    "            (output_list[i]['victory']==False) & \\\n",
    "            (output_list[i]['ascension_level']==20):\n",
    "                silent_asc20_lose_games.append(output_list[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm curious about character winrates.  Lets compare to the total games per character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate all summary statistics\n",
    "defect_winning = len(defect_asc20_win_games)\n",
    "defect_losing = len(defect_asc20_lose_games)\n",
    "defect_total = len(defect_asc20_win_games)+len(defect_asc20_lose_games)\n",
    "defect_winrate = defect_winning/defect_total\n",
    "\n",
    "# Calculate all summary statistics\n",
    "ironclad_winning = len(ironclad_asc20_win_games)\n",
    "ironclad_losing = len(ironclad_asc20_lose_games)\n",
    "ironclad_total = len(ironclad_asc20_win_games)+len(ironclad_asc20_lose_games)\n",
    "ironclad_winrate = ironclad_winning/ironclad_total\n",
    "\n",
    "# Calculate all summary statistics\n",
    "silent_winning = len(silent_asc20_win_games)\n",
    "silent_losing = len(silent_asc20_lose_games)\n",
    "silent_total = len(silent_asc20_win_games)+len(silent_asc20_lose_games)\n",
    "silent_winrate = silent_winning/silent_total\n",
    "\n",
    "\n",
    "asc20_games_summary = pd.DataFrame({'Character':['Defect','Ironclad','Silent'],\n",
    "                                    'Winning Games':[defect_winning,\n",
    "                                                     ironclad_winning,\n",
    "                                                     silent_winning],\n",
    "                                     'Total Games':[defect_total,\n",
    "                                                    ironclad_total,\n",
    "                                                    silent_total],\n",
    "                                     'Winrate':[defect_winrate,\n",
    "                                               ironclad_winrate,\n",
    "                                               silent_winrate]})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Character</th>\n",
       "      <th>Winning Games</th>\n",
       "      <th>Total Games</th>\n",
       "      <th>Winrate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Defect</td>\n",
       "      <td>1669</td>\n",
       "      <td>16863</td>\n",
       "      <td>0.098974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Ironclad</td>\n",
       "      <td>1716</td>\n",
       "      <td>14798</td>\n",
       "      <td>0.115962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Silent</td>\n",
       "      <td>1811</td>\n",
       "      <td>14278</td>\n",
       "      <td>0.126838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Character  Winning Games  Total Games   Winrate\n",
       "0    Defect           1669        16863  0.098974\n",
       "1  Ironclad           1716        14798  0.115962\n",
       "2    Silent           1811        14278  0.126838"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asc20_games_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would seem that although Defect is the most-played character, it has the lowest winrate.  This supports the claim that Defect is the hardest character (at least on Ascension 20).  In any case, we have 1669 victorious Defect Ascension 20 games, which should be adequate sample for clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to convert this list of JSON objects to a dataframe we can cluster.  Ideally, the shape of the data is one-row-per-game with columns for all the cards and relics. In order to do that, we'll want to create a vector of all unique cards and relics.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting Unique Cards and Relics  \n",
    "\n",
    "In order to get all unique cards and relics, we can simply pull all cards and relics from all games, then apply the `unique()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_game_decks = []\n",
    "all_game_relics = []\n",
    "\n",
    "for i in range(len(output_list)):\n",
    "    if output_list[i] is not None:\n",
    "        # ensure the run data has the deck and relics to avoid errors in rare cases\n",
    "        if ('master_deck' in dict(output_list[i])) and ('relics' in dict(output_list[i])):\n",
    "            all_game_decks.append(output_list[i]['master_deck'])\n",
    "            all_game_relics.append(output_list[i]['relics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Within each game, each card and relic needs to be pulled out into a flat list.\n",
    "all_cards = []\n",
    "\n",
    "for i in range(len(all_game_decks)):\n",
    "    for j in range(len(all_game_decks[i])):\n",
    "        all_cards.append(all_game_decks[i][j])\n",
    "        \n",
    "all_relics = []\n",
    "\n",
    "for i in range(len(all_game_relics)):\n",
    "    for j in range(len(all_game_relics[i])):\n",
    "        all_relics.append(all_game_relics[i][j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create unique lists\n",
    "unique_cards = list(np.unique(all_cards))\n",
    "unique_relics = list(np.unique(all_relics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3164"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_cards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "876"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_relics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we have 3164 unique cards and 876 unique relics.  This is a fair bit more than expected, so lets take a look at the head and tail of cards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6A',\n",
       " '6A+1',\n",
       " 'A Thousand Cuts',\n",
       " 'A Thousand Cuts+1',\n",
       " 'Abandon',\n",
       " 'Abandon+1',\n",
       " 'AbeCurse',\n",
       " 'AbsoluteMagnitude+1',\n",
       " 'Absolvement',\n",
       " 'Absolvement+1']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_cards[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vexMod:StarBlast',\n",
       " 'vexMod:StrikeStorm',\n",
       " 'vexMod:StrikeStorm+1',\n",
       " 'vexMod:Taunt+1',\n",
       " 'vexMod:TrainingStrike',\n",
       " 'vexMod:TrainingStrike+1',\n",
       " 'vexMod:UltimateCard',\n",
       " 'vexMod:VenomSigh',\n",
       " 'vexMod:VolumeVengeance']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_cards[-10:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This reveals two issues: there are the standard and \"+1\" versions of cards (players can upgrade cards once) as well as cards from game mods (essentially, player-made extensions of the game).  Thankfully, my domain expertise makes it fairly easy to know which cards aren't in the base game and it seems like most of the modded cards have a ':' in their name so they should be fairly easy to exclude.  \n",
    "\n",
    "After testing, it looks like there are a few other exceptions for specific mods that use a '\\_' in their name.  I'll go ahead and simply remove those cases as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_cards[:] = [s for s in unique_cards if '+' not in s \\\n",
    "                   and ':' not in s\\\n",
    "                   and '_' not in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "679"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_cards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In review of the new card list, I can still see some non-base cards, but I'm not too concerned with this affecting the final results due to the expected low frequency of those cards (0 in cases where the character isn't one of the base characters).  \n",
    "\n",
    "Next, the same cleansing will be applied to the relics. Generally speaking, relics have the same issue with mods as the cards, but there are not upgrades available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_relics[:] = [s for s in unique_relics if '_' not in s \\\n",
    "                   and ':' not in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "391"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_relics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, this isn't a perfect methodology, but since there are no flags for being a mod within the game data, it is difficult to use a single signal as a subsetting criteria to only the base game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "At this point, we can build a table of all unique cards and relics and then fill in Trues and Falses for whether the card was present per completed game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resource_table_generator(resource_input, game_input):\n",
    "    '''\n",
    "    input: a list of resources to be included in the rows of the table (i.e. cards and relics)\n",
    "           a list of JSON game data to go in the columns\n",
    "    output: a DataFrame indicating if each resource is in each game with a True or False\n",
    "    '''\n",
    "    # Build a 1-column table with the resources in each row\n",
    "    resource_table = pd.DataFrame({'Resource':resource_input})\n",
    "    \n",
    "    # determine the number of preceding zeroes to put in the game name for the column names\n",
    "    game_volume = len(game_input)\n",
    "    preceding_zeroes = len(str(game_volume)) # so if you have 1669 games, the first game will be 'game_0001'\n",
    "    \n",
    "    # For each game append a column and fill with True/False based on if the card is present\n",
    "    for i in range(len(game_input)):\n",
    "        # scrub the '+1's from the cards (just remove the string, not the card) so they'll match on the unique_cards list\n",
    "        game_deck = game_input[i]['master_deck']\n",
    "        for j in range(len(game_deck)):\n",
    "            game_deck[j] = game_deck[j].replace('+1','')\n",
    "        \n",
    "        # Create column name for the game\n",
    "        resource_table['game_'+str('{:0'+str(preceding_zeroes)+'d}').format(i+1)] = False # default to false\n",
    "        # For each resource, update to True if it is in the final game resources\n",
    "        for j in range(len(resource_table)):\n",
    "            if((resource_table['Resource'][j] in game_deck) or \\\n",
    "               (resource_table['Resource'][j] in game_input[i]['relics'])):\n",
    "                resource_table.iloc[j,i+1] = True\n",
    "    \n",
    "    return(resource_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defect Resource Table and Summary Frequency Tables\n",
    "\n",
    "Now, simply plug in the resources and the Defect Ascension 20 victorious games to get a complete table of whether each resource is present in each game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "defect_asc20_win_resources = resource_table_generator(unique_cards+unique_relics, defect_asc20_win_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Resource</th>\n",
       "      <th>game_0001</th>\n",
       "      <th>game_0002</th>\n",
       "      <th>game_0003</th>\n",
       "      <th>game_0004</th>\n",
       "      <th>game_0005</th>\n",
       "      <th>game_0006</th>\n",
       "      <th>game_0007</th>\n",
       "      <th>game_0008</th>\n",
       "      <th>game_0009</th>\n",
       "      <th>...</th>\n",
       "      <th>game_1660</th>\n",
       "      <th>game_1661</th>\n",
       "      <th>game_1662</th>\n",
       "      <th>game_1663</th>\n",
       "      <th>game_1664</th>\n",
       "      <th>game_1665</th>\n",
       "      <th>game_1666</th>\n",
       "      <th>game_1667</th>\n",
       "      <th>game_1668</th>\n",
       "      <th>game_1669</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6A</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>A Thousand Cuts</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Abandon</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>AbeCurse</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Absolvement</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1065</td>\n",
       "      <td>Winged Necklace</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1066</td>\n",
       "      <td>WingedGreaves</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1067</td>\n",
       "      <td>WristBlade</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1068</td>\n",
       "      <td>Yang</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1069</td>\n",
       "      <td>ZombieTooth</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1070 rows × 1670 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Resource  game_0001  game_0002  game_0003  game_0004  game_0005  \\\n",
       "0                  6A      False      False      False      False      False   \n",
       "1     A Thousand Cuts      False      False      False      False      False   \n",
       "2             Abandon      False      False      False      False      False   \n",
       "3            AbeCurse      False      False      False      False      False   \n",
       "4         Absolvement      False      False      False      False      False   \n",
       "...               ...        ...        ...        ...        ...        ...   \n",
       "1065  Winged Necklace      False      False      False      False      False   \n",
       "1066    WingedGreaves      False      False      False      False      False   \n",
       "1067       WristBlade      False      False      False      False      False   \n",
       "1068             Yang      False      False      False      False      False   \n",
       "1069      ZombieTooth      False      False      False      False      False   \n",
       "\n",
       "      game_0006  game_0007  game_0008  game_0009  ...  game_1660  game_1661  \\\n",
       "0         False      False      False      False  ...      False      False   \n",
       "1         False      False      False      False  ...      False      False   \n",
       "2         False      False      False      False  ...      False      False   \n",
       "3         False      False      False      False  ...      False      False   \n",
       "4         False      False      False      False  ...      False      False   \n",
       "...         ...        ...        ...        ...  ...        ...        ...   \n",
       "1065      False      False      False      False  ...      False      False   \n",
       "1066      False      False      False      False  ...      False      False   \n",
       "1067      False      False      False      False  ...      False      False   \n",
       "1068      False      False      False      False  ...      False      False   \n",
       "1069      False      False      False      False  ...      False      False   \n",
       "\n",
       "      game_1662  game_1663  game_1664  game_1665  game_1666  game_1667  \\\n",
       "0         False      False      False      False      False      False   \n",
       "1         False      False      False      False      False      False   \n",
       "2         False      False      False      False      False      False   \n",
       "3         False      False      False      False      False      False   \n",
       "4         False      False      False      False      False      False   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1065      False      False      False      False      False      False   \n",
       "1066      False      False      False      False      False      False   \n",
       "1067      False      False      False      False      False      False   \n",
       "1068      False      False      False      False      False      False   \n",
       "1069      False      False      False      False      False      False   \n",
       "\n",
       "      game_1668  game_1669  \n",
       "0         False      False  \n",
       "1         False      False  \n",
       "2         False      False  \n",
       "3         False      False  \n",
       "4         False      False  \n",
       "...         ...        ...  \n",
       "1065      False      False  \n",
       "1066      False      False  \n",
       "1067      False      False  \n",
       "1068      False      False  \n",
       "1069      False      False  \n",
       "\n",
       "[1070 rows x 1670 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "defect_asc20_win_resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It'd be useful to see the relative frequency of each resource in a separate summary table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "defect_resource_freq = pd.DataFrame({'Resource':defect_asc20_win_resources['Resource'],\n",
    "                                     'Frequency':defect_asc20_win_resources.sum(axis = 1)})\n",
    "defect_resource_freq = defect_resource_freq.sort_values(by = ['Frequency'], ascending = False).reset_index(drop=True)\n",
    "defect_resource_freq['Percent of Wins'] = defect_resource_freq['Frequency']/len(defect_asc20_win_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset to resources which are >0\n",
    "defect_resource_freq = defect_resource_freq[defect_resource_freq['Frequency']>0]\n",
    "defect_resource_freq['Percentile Rank']=defect_resource_freq['Frequency'].rank(pct=True, ascending = False)\n",
    "defect_resource_freq['Rank']=defect_resource_freq['Frequency'].rank(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Resource</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Percent of Wins</th>\n",
       "      <th>Percentile Rank</th>\n",
       "      <th>Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>AscendersBane</td>\n",
       "      <td>1646</td>\n",
       "      <td>0.986219</td>\n",
       "      <td>0.002488</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Dualcast</td>\n",
       "      <td>1513</td>\n",
       "      <td>0.906531</td>\n",
       "      <td>0.004975</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Zap</td>\n",
       "      <td>1401</td>\n",
       "      <td>0.839425</td>\n",
       "      <td>0.007463</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Cracked Core</td>\n",
       "      <td>1394</td>\n",
       "      <td>0.835231</td>\n",
       "      <td>0.009950</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Coolheaded</td>\n",
       "      <td>1357</td>\n",
       "      <td>0.813062</td>\n",
       "      <td>0.012438</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Defragment</td>\n",
       "      <td>1163</td>\n",
       "      <td>0.696824</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Hologram</td>\n",
       "      <td>1141</td>\n",
       "      <td>0.683643</td>\n",
       "      <td>0.017413</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Glacier</td>\n",
       "      <td>1039</td>\n",
       "      <td>0.622528</td>\n",
       "      <td>0.019900</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Cold Snap</td>\n",
       "      <td>931</td>\n",
       "      <td>0.557819</td>\n",
       "      <td>0.022388</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Capacitor</td>\n",
       "      <td>889</td>\n",
       "      <td>0.532654</td>\n",
       "      <td>0.024876</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Resource  Frequency  Percent of Wins  Percentile Rank  Rank\n",
       "0  AscendersBane       1646         0.986219         0.002488   1.0\n",
       "1       Dualcast       1513         0.906531         0.004975   2.0\n",
       "2            Zap       1401         0.839425         0.007463   3.0\n",
       "3   Cracked Core       1394         0.835231         0.009950   4.0\n",
       "4     Coolheaded       1357         0.813062         0.012438   5.0\n",
       "5     Defragment       1163         0.696824         0.014925   6.0\n",
       "6       Hologram       1141         0.683643         0.017413   7.0\n",
       "7        Glacier       1039         0.622528         0.019900   8.0\n",
       "8      Cold Snap        931         0.557819         0.022388   9.0\n",
       "9      Capacitor        889         0.532654         0.024876  10.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "defect_resource_freq[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results align with expectations.  'AscendersBane' is the curse card which should be present in every winning deck with Defect on Ascension 20 and thus, it makes sense that it's the most frequent card (though I'm not quire sure how some games completed without it).  Below that are the starting cards 'Dualcast' and 'Zap', then the starting relic 'Cracked Core'.  The first non-starting resource is 'Coolheaded' and it appears in a full **81%** of games! I knew it was a good card, but it seems almost critical to success on Ascension 20 with Defect.\n",
    "\n",
    "After having used this .csv when playing, it seems like it'd be more user-friendly to have a total of 3 .csvs per character.  We've created one (a view containing all relics and cards), but if I only wanted to select cards in the top 20th percentile, I can't because the relics are mixed in.  This being the case, we'll separate into cards and relics, then get the percentiles and ranks within those groupings.  \n",
    "\n",
    "To do this, we'll use a function to assign 'card' or 'relic' to `defect_resource_freq` in a 'resource_type' column, then subset on that before performing the ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resource_typer(resource_name_input):\n",
    "    '''\n",
    "    input: name of a resource\n",
    "    output: string of 'relic' or 'card' based on the input\n",
    "    '''\n",
    "    if resource_name_input in unique_cards: return('card')\n",
    "    if resource_name_input in unique_relics: return('relic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/willwright/.local/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "defect_resource_freq['Resource Type']=''\n",
    "for i in range(len(defect_resource_freq)):\n",
    "    defect_resource_freq['Resource Type'][i] = resource_typer(defect_resource_freq['Resource'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Resource</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Percent of Wins</th>\n",
       "      <th>Percentile Rank</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Resource Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>AscendersBane</td>\n",
       "      <td>1646</td>\n",
       "      <td>0.986219</td>\n",
       "      <td>0.002488</td>\n",
       "      <td>1.0</td>\n",
       "      <td>card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Dualcast</td>\n",
       "      <td>1513</td>\n",
       "      <td>0.906531</td>\n",
       "      <td>0.004975</td>\n",
       "      <td>2.0</td>\n",
       "      <td>card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Zap</td>\n",
       "      <td>1401</td>\n",
       "      <td>0.839425</td>\n",
       "      <td>0.007463</td>\n",
       "      <td>3.0</td>\n",
       "      <td>card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Cracked Core</td>\n",
       "      <td>1394</td>\n",
       "      <td>0.835231</td>\n",
       "      <td>0.009950</td>\n",
       "      <td>4.0</td>\n",
       "      <td>relic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Coolheaded</td>\n",
       "      <td>1357</td>\n",
       "      <td>0.813062</td>\n",
       "      <td>0.012438</td>\n",
       "      <td>5.0</td>\n",
       "      <td>card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Defragment</td>\n",
       "      <td>1163</td>\n",
       "      <td>0.696824</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>6.0</td>\n",
       "      <td>card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Hologram</td>\n",
       "      <td>1141</td>\n",
       "      <td>0.683643</td>\n",
       "      <td>0.017413</td>\n",
       "      <td>7.0</td>\n",
       "      <td>card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Glacier</td>\n",
       "      <td>1039</td>\n",
       "      <td>0.622528</td>\n",
       "      <td>0.019900</td>\n",
       "      <td>8.0</td>\n",
       "      <td>card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Cold Snap</td>\n",
       "      <td>931</td>\n",
       "      <td>0.557819</td>\n",
       "      <td>0.022388</td>\n",
       "      <td>9.0</td>\n",
       "      <td>card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Capacitor</td>\n",
       "      <td>889</td>\n",
       "      <td>0.532654</td>\n",
       "      <td>0.024876</td>\n",
       "      <td>10.0</td>\n",
       "      <td>card</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Resource  Frequency  Percent of Wins  Percentile Rank  Rank  \\\n",
       "0  AscendersBane       1646         0.986219         0.002488   1.0   \n",
       "1       Dualcast       1513         0.906531         0.004975   2.0   \n",
       "2            Zap       1401         0.839425         0.007463   3.0   \n",
       "3   Cracked Core       1394         0.835231         0.009950   4.0   \n",
       "4     Coolheaded       1357         0.813062         0.012438   5.0   \n",
       "5     Defragment       1163         0.696824         0.014925   6.0   \n",
       "6       Hologram       1141         0.683643         0.017413   7.0   \n",
       "7        Glacier       1039         0.622528         0.019900   8.0   \n",
       "8      Cold Snap        931         0.557819         0.022388   9.0   \n",
       "9      Capacitor        889         0.532654         0.024876  10.0   \n",
       "\n",
       "  Resource Type  \n",
       "0          card  \n",
       "1          card  \n",
       "2          card  \n",
       "3         relic  \n",
       "4          card  \n",
       "5          card  \n",
       "6          card  \n",
       "7          card  \n",
       "8          card  \n",
       "9          card  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "defect_resource_freq[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we simply subset on 'Resource Type' and re-apply the rank and percentile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cards\n",
    "defect_card_freq = copy.copy(defect_resource_freq[defect_resource_freq['Resource Type']=='card'])\n",
    "del defect_card_freq['Resource Type'] # redundant column since this is only cards\n",
    "defect_card_freq['Percentile Rank']=defect_card_freq['Frequency'].rank(pct=True, ascending = False)\n",
    "defect_card_freq['Rank']=defect_card_freq['Frequency'].rank(ascending = False)\n",
    "\n",
    "# relics\n",
    "defect_relic_freq = copy.copy(defect_resource_freq[defect_resource_freq['Resource Type']=='relic'])\n",
    "del defect_relic_freq['Resource Type'] # redundant column since this is only cards\n",
    "defect_relic_freq['Percentile Rank']=defect_relic_freq['Frequency'].rank(pct=True, ascending = False)\n",
    "defect_relic_freq['Rank']=defect_relic_freq['Frequency'].rank(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the framework complete for Defect, we can simply apply the same methodology to Silent and Ironclad:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Silent Resource Table and Summary Frequency Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create Resource Table\n",
    "silent_asc20_win_resources = resource_table_generator(unique_cards+unique_relics, silent_asc20_win_games)\n",
    "silent_resource_freq = pd.DataFrame({'Resource':silent_asc20_win_resources['Resource'],\n",
    "                                     'Frequency':silent_asc20_win_resources.sum(axis = 1)})\n",
    "silent_resource_freq = silent_resource_freq.sort_values(by = ['Frequency'], ascending = False).reset_index(drop=True)\n",
    "silent_resource_freq['Percent of Wins'] = silent_resource_freq['Frequency']/len(silent_asc20_win_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/willwright/.local/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "# subset to resources which are >0\n",
    "silent_resource_freq = silent_resource_freq[silent_resource_freq['Frequency']>0]\n",
    "silent_resource_freq['Percentile Rank']=silent_resource_freq['Frequency'].rank(pct=True, ascending = False)\n",
    "silent_resource_freq['Rank']=silent_resource_freq['Frequency'].rank(ascending = False)\n",
    "\n",
    "# add resource type\n",
    "silent_resource_freq['Resource Type']=''\n",
    "for i in range(len(silent_resource_freq)):\n",
    "    silent_resource_freq['Resource Type'][i] = resource_typer(silent_resource_freq['Resource'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create separate card and relic tables\n",
    "# cards\n",
    "silent_card_freq = copy.copy(silent_resource_freq[silent_resource_freq['Resource Type']=='card'])\n",
    "del silent_card_freq['Resource Type'] # redundant column since this is only cards\n",
    "silent_card_freq['Percentile Rank']=silent_card_freq['Frequency'].rank(pct=True, ascending = False)\n",
    "silent_card_freq['Rank']=silent_card_freq['Frequency'].rank(ascending = False)\n",
    "\n",
    "# relics\n",
    "silent_relic_freq = copy.copy(silent_resource_freq[silent_resource_freq['Resource Type']=='relic'])\n",
    "del silent_relic_freq['Resource Type'] # redundant column since this is only cards\n",
    "silent_relic_freq['Percentile Rank']=silent_relic_freq['Frequency'].rank(pct=True, ascending = False)\n",
    "silent_relic_freq['Rank']=silent_relic_freq['Frequency'].rank(ascending = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ironclad Resource Table and Summary Frequency Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Resource Table\n",
    "ironclad_asc20_win_resources = resource_table_generator(unique_cards+unique_relics, ironclad_asc20_win_games)\n",
    "ironclad_resource_freq = pd.DataFrame({'Resource':ironclad_asc20_win_resources['Resource'],\n",
    "                                     'Frequency':ironclad_asc20_win_resources.sum(axis = 1)})\n",
    "ironclad_resource_freq = ironclad_resource_freq.sort_values(by = ['Frequency'], ascending = False).reset_index(drop=True)\n",
    "ironclad_resource_freq['Percent of Wins'] = ironclad_resource_freq['Frequency']/len(ironclad_asc20_win_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/willwright/.local/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "# subset to resources which are >0\n",
    "ironclad_resource_freq = ironclad_resource_freq[ironclad_resource_freq['Frequency']>0]\n",
    "ironclad_resource_freq['Percentile Rank']=ironclad_resource_freq['Frequency'].rank(pct=True, ascending = False)\n",
    "ironclad_resource_freq['Rank']=ironclad_resource_freq['Frequency'].rank(ascending = False)\n",
    "\n",
    "# add resource type\n",
    "ironclad_resource_freq['Resource Type']=''\n",
    "for i in range(len(ironclad_resource_freq)):\n",
    "    ironclad_resource_freq['Resource Type'][i] = resource_typer(ironclad_resource_freq['Resource'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create separate card and relic tables\n",
    "# cards\n",
    "ironclad_card_freq = copy.copy(ironclad_resource_freq[ironclad_resource_freq['Resource Type']=='card'])\n",
    "del ironclad_card_freq['Resource Type'] # redundant column since this is only cards\n",
    "ironclad_card_freq['Percentile Rank']=ironclad_card_freq['Frequency'].rank(pct=True, ascending = False)\n",
    "ironclad_card_freq['Rank']=ironclad_card_freq['Frequency'].rank(ascending = False)\n",
    "\n",
    "# relics\n",
    "ironclad_relic_freq = copy.copy(ironclad_resource_freq[ironclad_resource_freq['Resource Type']=='relic'])\n",
    "del ironclad_relic_freq['Resource Type'] # redundant column since this is only cards\n",
    "ironclad_relic_freq['Percentile Rank']=ironclad_relic_freq['Frequency'].rank(pct=True, ascending = False)\n",
    "ironclad_relic_freq['Rank']=ironclad_relic_freq['Frequency'].rank(ascending = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving Frequency Table Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to .csv\n",
    "# Defect\n",
    "defect_resource_freq.to_csv('../results/defect_resource_freq.csv', index = False)\n",
    "defect_card_freq.to_csv('../results/defect_card_freq.csv', index = False)\n",
    "defect_relic_freq.to_csv('../results/defect_relic_freq.csv', index = False)\n",
    "\n",
    "# Silent\n",
    "silent_resource_freq.to_csv('../results/silent_resource_freq.csv', index = False)\n",
    "silent_card_freq.to_csv('../results/silent_card_freq.csv', index = False)\n",
    "silent_relic_freq.to_csv('../results/silent_relic_freq.csv', index = False)\n",
    "\n",
    "# Ironclad\n",
    "ironclad_resource_freq.to_csv('../results/ironclad_resource_freq.csv', index = False)\n",
    "ironclad_card_freq.to_csv('../results/ironclad_card_freq.csv', index = False)\n",
    "ironclad_relic_freq.to_csv('../results/ironclad_relic_freq.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Clustering the data  \n",
    "In the 'clustering_algorithm_methodology_testing' notebook, an unsupervised binary clustering algorithm was devised. Details about this method can be reviewed within that notebook, however, in this script, we'll simply be pulling in and applying the resulting functions.  \n",
    "\n",
    "That said, from a high level, the algorithm works as follows:\n",
    "1. Start with nodes equal to the number of games (k=m)\n",
    "2. Calculate the distance between each node and every other node where distance is the sum of resources that don't match (i.e. if a card is in both decks, that resource adds 0 distance, but it if is in one and not the other, then it adds 1 distance.  \"Distance\" is the sum of all these resource differences)\n",
    "3. For each node, calculate the nearest node(s) via distance + tolerance and add to the node via averaging. \n",
    "4. For each updated node, calculate the distances to all other nodes and the min and max distances per node\n",
    "5. Drop the node for which the min distance is the smallest and, of those, the max distance is the smallest (this steps adds maximum distance between the nodes)\n",
    "6. Repeat 2-5 until k=1\n",
    "7. Review average distances for k=1 through k=m\n",
    "8. Select a reasonable k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_distance_calculator(cluster1_input, cluster2_input):\n",
    "    '''\n",
    "    input: arrays of binary data for two clusters\n",
    "    output: a distance measurement\n",
    "    method: distance is the sum of differences in the binary data, by position\n",
    "    '''\n",
    "    distance = sum(abs(cluster1_input-cluster2_input))\n",
    "    return(distance)\n",
    "\n",
    "def cluster_confusioner(cluster_list_input):\n",
    "    '''\n",
    "    input: a list of clusters of equal length\n",
    "    output: a matrix which applies the cluster_distance_calculator to each pair of clusters\n",
    "    '''\n",
    "    distance_matrix = np.empty((len(cluster_list_input), len(cluster_list_input)))\n",
    "    \n",
    "    # iterate through each comparison to populate the matrix\n",
    "    for i in range(len(cluster_list_input)):\n",
    "        for j in range(len(cluster_list_input)):\n",
    "            distance_matrix[i,j] = cluster_distance_calculator(cluster_list_input[i], cluster_list_input[j])\n",
    "    \n",
    "    return(distance_matrix)\n",
    "\n",
    "def cluster_creator(medoid_input, difference_percent_range, n_games):\n",
    "    '''\n",
    "    input: medoid_input is a one-dimensional array of binary data\n",
    "           difference_percent_range is a list with a min and max percent (e.g. [0,0.25] for 0-25%); cannot do <1% \n",
    "           n_games is the number of games needed in the output\n",
    "    output: a list of n games with the speficied similarity to the medoid_input\n",
    "    '''\n",
    "    \n",
    "    simulated_games = []\n",
    "    \n",
    "    for i in range(n_games):\n",
    "        # select how many elements will be changed\n",
    "        # must multiply by 100 and add 1 due to randrange needing integers and being exclusive with the high end\n",
    "        percent_change = random.randrange(difference_percent_range[0]*100, (difference_percent_range[1]+0.01)*100, 1)/100\n",
    "        \n",
    "        # convert the percent to an integer by multiplying by the total number of elements and rounding\n",
    "        element_change = round(len(medoid_input)*percent_change)\n",
    "        \n",
    "        # select which elements will be changed\n",
    "        element_change_positions = []\n",
    "        for j in range(element_change):\n",
    "            element_change_positions.append(random.randrange(0,len(medoid_input)))\n",
    "        \n",
    "        # change those elements\n",
    "        simulated_game = copy.copy(medoid_input)\n",
    "        for k in range(len(element_change_positions)):\n",
    "            if simulated_game[element_change_positions[k]]==1:\n",
    "                simulated_game[element_change_positions[k]]=0\n",
    "            else:\n",
    "                simulated_game[element_change_positions[k]]=1\n",
    "        \n",
    "        # append to list of games\n",
    "        simulated_games.append(simulated_game)\n",
    "    \n",
    "    return(simulated_games)\n",
    "\n",
    "def node_distancer(resource_dataframe_input):\n",
    "    '''\n",
    "    input: resouce_dataframe_input is a dataframe with resources in the columns and games in the rows with \n",
    "            binary data filling the table.\n",
    "           k_input is the number of clusters\n",
    "    output: k centroids\n",
    "    '''\n",
    "    # create empty array to hold all the distances comparing each combination\n",
    "    all_node_distances = np.zeros([len(resource_dataframe_input),len(resource_dataframe_input)])\n",
    "    # calculate distance between the ith game and the jth game\n",
    "    for i in range(len(all_node_distances)):\n",
    "        for j in range(len(all_node_distances)):\n",
    "            all_node_distances[i,j] = cluster_distance_calculator(resource_dataframe_input.iloc[i], resource_dataframe_input.iloc[j])\n",
    "    \n",
    "    return(all_node_distances)\n",
    "\n",
    "def node_averager(list_of_nodes):\n",
    "    return(np.mean((list_of_nodes), axis = 0))\n",
    "\n",
    "def new_noder(node_table_input, node_distance_table_input, node_index, tolerance_input):\n",
    "    '''\n",
    "    inputs: resource_table_input: a table with games in the rows and resources in the columns (mxn)\n",
    "            node_distance_table_input: an array of node distances (mxm)\n",
    "            node_index: an integer value (should range from 0 to m)\n",
    "            tolderance_input: value to be added to the minimum distance to be included in the closest nodes\n",
    "    output: a tuple of a new average node and a list of the nodes averaged together\n",
    "    '''\n",
    "    node_distances = node_distance_table_input[node_index]\n",
    "    min_distance = min(node_distances[1:])+tolerance_input # find the closest node(s) that aren't the primary node\n",
    "    closest_node_indices = np.where(node_distances<=min_distance)[0] # [0] since these are 1-dimensional slices\n",
    "    \n",
    "    # grab the closest nodes and put into a list\n",
    "    closest_nodes = []\n",
    "    for i in range(len(closest_node_indices)):\n",
    "        closest_nodes.append(node_table_input.iloc[closest_node_indices[i]].values)\n",
    "    \n",
    "    # grab primary_node and add to the list of closest_nodes\n",
    "    primary_node = node_table_input.iloc[node_index].values\n",
    "    closest_nodes.append(primary_node)\n",
    "    \n",
    "    \n",
    "    # take an average of the primary and closest node(s)\n",
    "    new_node = node_averager(closest_nodes)\n",
    "    \n",
    "    return([new_node,[node_index,closest_node_indices]])\n",
    "    \n",
    "def node_updater(node_table_input, node_distance_table_input, tolerance_input = 1):\n",
    "    '''\n",
    "    TODO: add deets\n",
    "    '''\n",
    "    new_resource_list = []\n",
    "    for i in range(len(node_table_input)):\n",
    "        new_resource_list.append(new_noder(node_table_input, node_distance_table_input,i,tolerance_input)[0])\n",
    "    \n",
    "    # convert to dataframe\n",
    "    updated_node_table = pd.DataFrame(np.array(new_resource_list))\n",
    "    \n",
    "    return(updated_node_table)\n",
    "\n",
    "def node_distance_min_maxer(node_distance_table_input):\n",
    "    node_min_maxs= []\n",
    "    for i in range(len(node_distance_table_input)):\n",
    "        node_min = min(node_distance_table_input[i][[s for s in list(range(len(node_distance_table_input[i]))) \\\n",
    "                                                     if s != i]])\n",
    "        node_max = max(node_distance_table_input[i])\n",
    "        node_min_maxs.append([node_min, node_max])\n",
    "    return(node_min_maxs)\n",
    "\n",
    "def extract_nth(list_input, n): \n",
    "    return [element[n] for element in list_input] \n",
    "\n",
    "def drop_closest_nodes(node_table_input, node_minmax_distances):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    # calculate the min distance of the first element in each of the min/max lists\n",
    "    min_distance = min(extract_nth(node_minmax_distances,0))\n",
    "    \n",
    "    # calculate indices of the nodes which contain the minimum\n",
    "    node_min_indices = np.where(extract_nth(node_minmax_distances,0)==min_distance)[0]\n",
    "    \n",
    "    # generate a list of min/max distances for the nodes which contain the min distance\n",
    "    min_distance_node_distances = [node_minmax_distances[i] for i in node_min_indices]\n",
    "    \n",
    "    # of those distances, calculate the minimum max distance (the second element in the distance lists)\n",
    "    minmax_distance = min(extract_nth(min_distance_node_distances,1))\n",
    "    \n",
    "    # create an array containing the mininum and minimum maximum distance\n",
    "    node_removal_distances = np.asarray([min_distance, minmax_distance])\n",
    "    \n",
    "    # calculate the node indices from the distance table which match the node_removal_distances\n",
    "    node_removal_indices = np.where((extract_nth(node_minmax_distances,0)==node_removal_distances[0]) &\\\n",
    "                                (extract_nth(node_minmax_distances,1)==node_removal_distances[1]))[0]\n",
    "    \n",
    "    # drop the specified nodes from the resource table\n",
    "    reduced_node_table = node_table_input.drop(node_removal_indices)\n",
    "    \n",
    "    return(reduced_node_table)\n",
    "\n",
    "def node_reducer(node_dataframe_input, tolerance_input):\n",
    "    '''\n",
    "    input: a dataframe with nodes in the rows and binary features in the columns\n",
    "    output: a reduced version of the input table which creates hybrid nodes and removes the node(s) for which there is\n",
    "        the least difference to the other nodes.\n",
    "    '''\n",
    "    \n",
    "    # calculate node distances\n",
    "    node_distances = node_distancer(node_dataframe_input)\n",
    "    \n",
    "    # create new hybrid nodes\n",
    "    new_nodes = node_updater(node_dataframe_input, node_distances, tolerance_input)\n",
    "    \n",
    "    # calculate hybrid node distances\n",
    "    new_node_distances = node_distancer(new_nodes)\n",
    "    \n",
    "    # calculate the min and max distances per new hybrid node\n",
    "    new_node_minmax_distances = node_distance_min_maxer(new_node_distances)\n",
    "    \n",
    "    # drop the closest node(s)\n",
    "    reduced_node_dataframe = drop_closest_nodes(new_nodes, new_node_minmax_distances)\n",
    "    \n",
    "    return(reduced_node_dataframe)\n",
    "\n",
    "def binary_clusterer(node_dataframe_input, tolerance_input):\n",
    "    '''\n",
    "    input: node_dataframe_input: a dataframe with nodes in the rows and binary features in the columns\n",
    "           tolerance_input: value to be added to the minimum distance to be included in the closest nodes\n",
    "    output: clusters: for each step, the resulting hybrid clusters\n",
    "            average_distances: for each step, the resulting average distance to every other cluster\n",
    "            k: the number of centroids\n",
    "    '''\n",
    "    centroids = []\n",
    "    average_distances = []\n",
    "    ks = []\n",
    "    node_dataframe = node_dataframe_input\n",
    "      \n",
    "    k = len(node_dataframe_input)\n",
    "    \n",
    "    while k>=1:\n",
    "        # save results of current step\n",
    "        centroids.append(node_dataframe)\n",
    "        average_distances.append(np.mean(np.mean(node_distancer(node_dataframe), axis = 0)))\n",
    "        ks.append(k)\n",
    "        \n",
    "        # reduce node_dataframe\n",
    "        node_dataframe = node_reducer(node_dataframe, tolerance_input)\n",
    "        \n",
    "        # set k\n",
    "        k = len(node_dataframe)\n",
    "        \n",
    "    return([centroids,average_distances,ks])\n",
    "\n",
    "def cluster_classifier(node_table_input, cluster_centroids):\n",
    "    clusters = []\n",
    "    \n",
    "    for i in range(len(node_table_input)):\n",
    "        node_distances = []\n",
    "        \n",
    "        # get distance to each cluster centroid:\n",
    "        for j in range(len(cluster_centroids)):\n",
    "            node_distances.append(cluster_distance_calculator(node_table_input.iloc[i], cluster_centroids.iloc[j]))\n",
    "        \n",
    "        min_distance = min(node_distances)\n",
    "        \n",
    "        clusters.append(np.where(np.asarray(node_distances)==min_distance)[0][0])\n",
    "    \n",
    "    return(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
